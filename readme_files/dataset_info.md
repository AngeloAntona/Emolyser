# DEAM (Dataset for Emotion Analysis in Music)

Overview
DEAM is designed for emotion analysis in music, supporting research in Music Information Retrieval (MIR), machine learning, and affective computing.

Content
- **Music Tracks**: Short excerpts (around 45 seconds) from various genres and styles, covering a wide emotional range.
- **Annotations**:
  - *Valence and Arousal Ratings*: Measure positivity/negativity and emotional intensity.
  - *Continuous Annotations*: Capture how emotions evolve over time in a track.
  - *Static Annotations*: Global values summarizing the overall emotional impression.
- **Metadata**: Includes information on genre, tempo, and other musical features.

Applications
- Emotion recognition and classification in music.
- Study of dynamic emotional responses.
- Training and validation of ML models for MIR.


# EMOPIA (EMOtional POPIAno Dataset)

Overview
EMOPIA focuses on the emotional dimension of pop piano, contributing to studies in MIR, music generation, and computational musicology.

Content
- **Piano Tracks**: MIDI files of expressively played pop piano pieces, covering a wide range of emotional nuances.
- **Annotations**:
  - *Emotion Quadrants* (Russell's circular model): Q1 (happy, excited), Q2 (angry, tense), Q3 (sad, melancholic), Q4 (calm, relaxed).
  - *Valence and Arousal Scores*: Indicating positivity and emotional intensity.
- **Performance Dynamics**: Data on velocity, tempo, and timing, capturing expressive nuances.

Applications
- Emotion classification and emotional music composition.
- Analysis of expressiveness in piano performance.
